{"cells":[{"cell_type":"markdown","metadata":{"id":"FhfzkI1rsOhH"},"source":["# Voorspellen van credit card fraude\n","Een bekende dataset op Kaggle is de Credit Card Fraud Detection dataset. Je vindt meer informatie hierover via deze link: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n","\n","In deze opdracht gaan we weer aan de slag met deze dataset. Het doel is om zoveel mogelijk credit card fraude te herkennen, nu aan de hand van zogenaamde 'Tree Based' algoritmes. In dit notebook behandelen we onder andere random forest en twee boosting algoritmes.\n","\n","- Voer onderstaande cel uit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JyHkJUu1sOhK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25949,"status":"ok","timestamp":1675850682602,"user":{"displayName":"Nurtan Bilmis","userId":"08002031282163870915"},"user_tz":-60},"id":"GpthFrtld6WS","outputId":"0bb1d1a7-b00c-4108-e52d-87c6575730de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"jrFEYr9BsOhM"},"source":["### 1A Inlezen data\n","- Lees de data in creditcard.csv in als een dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DFoH_i2sOhM"},"outputs":[],"source":["df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MakeITWork/Week_10/creditcard.csv').dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tg3mBsv4s1Vl"},"outputs":[],"source":["df.drop(['Time', 'Amount'], axis = 1, inplace = True)"]},{"cell_type":"markdown","metadata":{"id":"-Dll7zODsOhM"},"source":["## 2 Bagging"]},{"cell_type":"markdown","metadata":{"id":"_PeQ3L5osOhN"},"source":["### 2A Bagging terminologie\n","- Leg uit wat bagging is? Gebruik daarbij onder andere de termen 'bootstrap' en 'steekproef met terugleggen'.\n","- Leg uit hoe een bagging model wordt getraind.\n","- Leg uit hoe voorspellingen tot stond komen voor een bagging model. Leg dit uit voor zowel een classificatie-model als voor een regressie-model."]},{"cell_type":"markdown","metadata":{"id":"ecQvGhlb68F-"},"source":[" - Bagging means bootstrap aggregation. Uses different subset of the data.\n"," - Reduces variance of individual models.\n"," - Bagging takes n models bootstrap samples from the training set to train n models. \n"," - Predictions by majority voting for BaggingClassifier\n"," - Predictions through averaging for BaggingRegressor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":236,"status":"ok","timestamp":1675850738717,"user":{"displayName":"Nurtan Bilmis","userId":"08002031282163870915"},"user_tz":-60},"id":"EGEFPOS8JW3n","outputId":"ce443916-4725-435a-85bd-11c4f9138608"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-49034724-a8f7-42df-9575-e7049933aac8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>V10</th>\n","      <th>...</th>\n","      <th>V20</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1.359807</td>\n","      <td>-0.072781</td>\n","      <td>2.536347</td>\n","      <td>1.378155</td>\n","      <td>-0.338321</td>\n","      <td>0.462388</td>\n","      <td>0.239599</td>\n","      <td>0.098698</td>\n","      <td>0.363787</td>\n","      <td>0.090794</td>\n","      <td>...</td>\n","      <td>0.251412</td>\n","      <td>-0.018307</td>\n","      <td>0.277838</td>\n","      <td>-0.110474</td>\n","      <td>0.066928</td>\n","      <td>0.128539</td>\n","      <td>-0.189115</td>\n","      <td>0.133558</td>\n","      <td>-0.021053</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.191857</td>\n","      <td>0.266151</td>\n","      <td>0.166480</td>\n","      <td>0.448154</td>\n","      <td>0.060018</td>\n","      <td>-0.082361</td>\n","      <td>-0.078803</td>\n","      <td>0.085102</td>\n","      <td>-0.255425</td>\n","      <td>-0.166974</td>\n","      <td>...</td>\n","      <td>-0.069083</td>\n","      <td>-0.225775</td>\n","      <td>-0.638672</td>\n","      <td>0.101288</td>\n","      <td>-0.339846</td>\n","      <td>0.167170</td>\n","      <td>0.125895</td>\n","      <td>-0.008983</td>\n","      <td>0.014724</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.358354</td>\n","      <td>-1.340163</td>\n","      <td>1.773209</td>\n","      <td>0.379780</td>\n","      <td>-0.503198</td>\n","      <td>1.800499</td>\n","      <td>0.791461</td>\n","      <td>0.247676</td>\n","      <td>-1.514654</td>\n","      <td>0.207643</td>\n","      <td>...</td>\n","      <td>0.524980</td>\n","      <td>0.247998</td>\n","      <td>0.771679</td>\n","      <td>0.909412</td>\n","      <td>-0.689281</td>\n","      <td>-0.327642</td>\n","      <td>-0.139097</td>\n","      <td>-0.055353</td>\n","      <td>-0.059752</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.966272</td>\n","      <td>-0.185226</td>\n","      <td>1.792993</td>\n","      <td>-0.863291</td>\n","      <td>-0.010309</td>\n","      <td>1.247203</td>\n","      <td>0.237609</td>\n","      <td>0.377436</td>\n","      <td>-1.387024</td>\n","      <td>-0.054952</td>\n","      <td>...</td>\n","      <td>-0.208038</td>\n","      <td>-0.108300</td>\n","      <td>0.005274</td>\n","      <td>-0.190321</td>\n","      <td>-1.175575</td>\n","      <td>0.647376</td>\n","      <td>-0.221929</td>\n","      <td>0.062723</td>\n","      <td>0.061458</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1.158233</td>\n","      <td>0.877737</td>\n","      <td>1.548718</td>\n","      <td>0.403034</td>\n","      <td>-0.407193</td>\n","      <td>0.095921</td>\n","      <td>0.592941</td>\n","      <td>-0.270533</td>\n","      <td>0.817739</td>\n","      <td>0.753074</td>\n","      <td>...</td>\n","      <td>0.408542</td>\n","      <td>-0.009431</td>\n","      <td>0.798278</td>\n","      <td>-0.137458</td>\n","      <td>0.141267</td>\n","      <td>-0.206010</td>\n","      <td>0.502292</td>\n","      <td>0.219422</td>\n","      <td>0.215153</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>284802</th>\n","      <td>-11.881118</td>\n","      <td>10.071785</td>\n","      <td>-9.834783</td>\n","      <td>-2.066656</td>\n","      <td>-5.364473</td>\n","      <td>-2.606837</td>\n","      <td>-4.918215</td>\n","      <td>7.305334</td>\n","      <td>1.914428</td>\n","      <td>4.356170</td>\n","      <td>...</td>\n","      <td>1.475829</td>\n","      <td>0.213454</td>\n","      <td>0.111864</td>\n","      <td>1.014480</td>\n","      <td>-0.509348</td>\n","      <td>1.436807</td>\n","      <td>0.250034</td>\n","      <td>0.943651</td>\n","      <td>0.823731</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>284803</th>\n","      <td>-0.732789</td>\n","      <td>-0.055080</td>\n","      <td>2.035030</td>\n","      <td>-0.738589</td>\n","      <td>0.868229</td>\n","      <td>1.058415</td>\n","      <td>0.024330</td>\n","      <td>0.294869</td>\n","      <td>0.584800</td>\n","      <td>-0.975926</td>\n","      <td>...</td>\n","      <td>0.059616</td>\n","      <td>0.214205</td>\n","      <td>0.924384</td>\n","      <td>0.012463</td>\n","      <td>-1.016226</td>\n","      <td>-0.606624</td>\n","      <td>-0.395255</td>\n","      <td>0.068472</td>\n","      <td>-0.053527</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>284804</th>\n","      <td>1.919565</td>\n","      <td>-0.301254</td>\n","      <td>-3.249640</td>\n","      <td>-0.557828</td>\n","      <td>2.630515</td>\n","      <td>3.031260</td>\n","      <td>-0.296827</td>\n","      <td>0.708417</td>\n","      <td>0.432454</td>\n","      <td>-0.484782</td>\n","      <td>...</td>\n","      <td>0.001396</td>\n","      <td>0.232045</td>\n","      <td>0.578229</td>\n","      <td>-0.037501</td>\n","      <td>0.640134</td>\n","      <td>0.265745</td>\n","      <td>-0.087371</td>\n","      <td>0.004455</td>\n","      <td>-0.026561</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>284805</th>\n","      <td>-0.240440</td>\n","      <td>0.530483</td>\n","      <td>0.702510</td>\n","      <td>0.689799</td>\n","      <td>-0.377961</td>\n","      <td>0.623708</td>\n","      <td>-0.686180</td>\n","      <td>0.679145</td>\n","      <td>0.392087</td>\n","      <td>-0.399126</td>\n","      <td>...</td>\n","      <td>0.127434</td>\n","      <td>0.265245</td>\n","      <td>0.800049</td>\n","      <td>-0.163298</td>\n","      <td>0.123205</td>\n","      <td>-0.569159</td>\n","      <td>0.546668</td>\n","      <td>0.108821</td>\n","      <td>0.104533</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>284806</th>\n","      <td>-0.533413</td>\n","      <td>-0.189733</td>\n","      <td>0.703337</td>\n","      <td>-0.506271</td>\n","      <td>-0.012546</td>\n","      <td>-0.649617</td>\n","      <td>1.577006</td>\n","      <td>-0.414650</td>\n","      <td>0.486180</td>\n","      <td>-0.915427</td>\n","      <td>...</td>\n","      <td>0.382948</td>\n","      <td>0.261057</td>\n","      <td>0.643078</td>\n","      <td>0.376777</td>\n","      <td>0.008797</td>\n","      <td>-0.473649</td>\n","      <td>-0.818267</td>\n","      <td>-0.002415</td>\n","      <td>0.013649</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>284807 rows Ã— 29 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49034724-a8f7-42df-9575-e7049933aac8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-49034724-a8f7-42df-9575-e7049933aac8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-49034724-a8f7-42df-9575-e7049933aac8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["               V1         V2        V3        V4        V5        V6  \\\n","0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n","1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n","2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n","3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n","4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n","...           ...        ...       ...       ...       ...       ...   \n","284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n","284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n","284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n","284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n","284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n","\n","              V7        V8        V9       V10  ...       V20       V21  \\\n","0       0.239599  0.098698  0.363787  0.090794  ...  0.251412 -0.018307   \n","1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775   \n","2       0.791461  0.247676 -1.514654  0.207643  ...  0.524980  0.247998   \n","3       0.237609  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300   \n","4       0.592941 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431   \n","...          ...       ...       ...       ...  ...       ...       ...   \n","284802 -4.918215  7.305334  1.914428  4.356170  ...  1.475829  0.213454   \n","284803  0.024330  0.294869  0.584800 -0.975926  ...  0.059616  0.214205   \n","284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.001396  0.232045   \n","284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.127434  0.265245   \n","284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.382948  0.261057   \n","\n","             V22       V23       V24       V25       V26       V27       V28  \\\n","0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n","1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n","2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n","3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n","4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n","...          ...       ...       ...       ...       ...       ...       ...   \n","284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n","284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n","284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n","284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n","284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n","\n","        Class  \n","0           0  \n","1           0  \n","2           0  \n","3           0  \n","4           0  \n","...       ...  \n","284802      0  \n","284803      0  \n","284804      0  \n","284805      0  \n","284806      0  \n","\n","[284807 rows x 29 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"O9G_fJKdsOhO"},"source":["### 2B train-test plit\n","- Splits de data in X en y\n","- Splits de data in trainsets en testsets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235,"status":"ok","timestamp":1675850743248,"user":{"displayName":"Nurtan Bilmis","userId":"08002031282163870915"},"user_tz":-60},"id":"I9LR-OJM8Shq","outputId":"91c3b44b-96f9-49bc-cea9-245632ffffaa"},"outputs":[{"data":{"text/plain":["False"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().any().any()"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":554,"status":"ok","timestamp":1675864348268,"user":{"displayName":"Nurtan Bilmis","userId":"08002031282163870915"},"user_tz":-60},"id":"IjbxRR6MsOhO"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X = df.drop(\"Class\", axis=1)\n","y = df[\"Class\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)"]},{"cell_type":"markdown","metadata":{"id":"HVE6mSxfsOhP"},"source":["### 2C importeren\n","- importeer van sklearn:\n","    - Bagging classifier\n","    - Decision Tree classifier\n","    - f1 score"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":287,"status":"ok","timestamp":1675864350760,"user":{"displayName":"Nurtan Bilmis","userId":"08002031282163870915"},"user_tz":-60},"id":"hOJGeiDBsOhP"},"outputs":[],"source":["from sklearn.ensemble import BaggingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import f1_score"]},{"cell_type":"markdown","metadata":{"id":"9hOx1edusOhP"},"source":["### 2D Bagging vs Decision Tree\n","- \"Instantiate\" een decision tree classifier volgens onderstaande schermprint\n","- \"Instantiate\" een bagging classifier voor deze decision tree classifier. Kies voor 100 trees en kies een random state.\n","- Fit de bagging classifier op de trainingsdata\n","- Maak voorspellingen voor de testdata\n","- Vergelijk de resultaten voor de bagging classifier met de resultaten uit onderstaande schermprint.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5QlL1nKvsOhQ"},"outputs":[],"source":["tree = DecisionTreeClassifier(max_depth=10, criterion=\"entropy\", random_state=0)\n","bc = BaggingClassifier(base_estimator=tree, n_estimators=100, n_jobs=-1, max_features=1.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rkywFP9A9obK"},"outputs":[],"source":["bc.fit(X_train, y_train)\n","y_pred = bc.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1675852635208,"user":{"displayName":"Nurtan Bilmis","userId":"08002031282163870915"},"user_tz":-60},"id":"rWzbG0H-inf0","outputId":"e4cc951d-cd6e-476e-a803-3cafdf7dd051"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8202247191011237\n"]}],"source":["score = f1_score(y_test, y_pred)\n","print(score)"]},{"cell_type":"markdown","metadata":{"id":"BXhJtLJEsOhX"},"source":["## 3 Random Forest"]},{"cell_type":"markdown","metadata":{"id":"79LW6b74sOhX"},"source":["### 3A RF terminologie\n","- Leg uit hoe een random forest wordt opgebouwd en beschrijf het belangrijkste verschil tussen een random forest en bagging."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EENpcKO8JmPU"},"outputs":[],"source":["\"\"\"\n","Bagging:\n","- Base estimator can be any model : decision tree, logistic regression, meural network.\n","- Each estimator is trained on a distinct bootstrap sample of the training set\n","- Estimators use all features for training and prediction.\n","\n","Random forest:\n","- Base estimator is Decision Tree\n","- Bootstrap samples have the same size as the training set\n","- Further randomization in the training of individual trees.\n","- So it doesnt use all the futures for sampling.\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"_EUemAHrsOhY"},"source":["### 3C Random forest toepassen\n","- Pas een random forest model toe met als parameters:\n","    - criterion: entropy\n","    - aantal 'trees' : 100\n","    - maximale diepte: 10\n","- Bepaal de f1 score voor de test set.\n","- Vergelijk het resultaat met de 'bagging' methode."]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3mY1ihfgsOhY","executionInfo":{"status":"ok","timestamp":1675865998086,"user_tz":-60,"elapsed":201132,"user":{"displayName":"Nurtan Bilmis","userId":"08002031282163870915"}},"outputId":"f7325235-9494-4365-af84-307a9dd06e1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8324324324324324\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y random_state=0)\n","forest = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n","\n","forest.fit(X_train, y_train)\n","y_pred = forest.predict(X_test)\n","test_score = f1_score(y_test, y_pred)\n","print(test_score)"]},{"cell_type":"markdown","metadata":{"id":"wclI0GVNsOhZ"},"source":["### 4A feature importances\n","- Toon een barplot met daarin de feature importances van de random forest\n","- Leg uit hoe je dit overzicht kunt interpreteren\n","- Wat kun je hieruit wel opmaken, maar wat ook niet?"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":419,"status":"ok","timestamp":1675866003881,"user":{"displayName":"Nurtan Bilmis","userId":"08002031282163870915"},"user_tz":-60},"id":"1noR2f-osOha","outputId":"0d5a6083-fea7-4da6-ea20-632ac02e3b13","scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["from pandas.core.algorithms import searchsorted\n","import matplotlib.pyplot as plt\n","\n","importances = pd.Series(forest.feature_importances_, index = X.columns)\n","                                 \n","sorted = importances.sort_values()   \n","\n","sorted.plot(kind='barh', color='purple'); plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"CIBUBgGBfgil"},"source":["### 5A Boosting terminologie\n","- Leg uit hoe boosting werkt? Gebruik hierbij o.a. de term \"weak learner\" en lege deze uit.\n","- Leg uit hoe ADA boosting werkt. Gebruik hierbij o.a. de term wegingsfactor en leg deze uit.\n","- Leg uit hoe gradient boosting werkt. Gebruik hierbij o.a. de term \"errors\" en leg deze uit."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipgPLy53EAya"},"outputs":[],"source":["# Boosting is an ensemble method combining several \"weak learner\" models to form a strong learner."]},{"cell_type":"markdown","metadata":{"id":"NpbUb9zvgsPd"},"source":["### 5B ADA boosting\n","- Train een ADA Boosting classifier, maak daarbij een \"educated guess\" voor de parameter max_depth en het aantal trees.\n","- Beoordeel de uitkomst aan de hand van de f1 score\n"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"executionInfo":{"elapsed":152903,"status":"error","timestamp":1675866161692,"user":{"displayName":"Nurtan Bilmis","userId":"08002031282163870915"},"user_tz":-60},"id":"N3bttlA-sOhb","outputId":"c131967a-46b5-4fd5-99cb-0f775cfd5e04"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-4c247142add3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcardano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# score = f1_score(y_test, y_pred_proba)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \"\"\"\n\u001b[0;32m-> 1123\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1124\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \"\"\"\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"]}],"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n","                                                    stratify=y,    \n","                                                    random_state=0)\n","\n","tree3 = DecisionTreeClassifier(max_depth=1, random_state=0)\n","cardano = AdaBoostClassifier(base_estimator=tree3, n_estimators=100)\n","cardano.fit(X_train, y_train)\n","y_pred_proba = cardano.predict_proba(X_test)[:,1]\n","# score = f1_score(y_test, y_pred_proba)\n","print(f1_score(y_test, y_pred_proba))\n"]},{"cell_type":"markdown","metadata":{"id":"QNlvsy-4E9Mb"},"source":["### 5C Gradient boosting\n","- Train een ADA Boosting classifier, maak daarbij een \"educated guess\" voor de parameter max_depth en het aantal trees (estimators).\n","- Beoordeel de uitkomst aan de hand van de f1 score"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1675866161694,"user":{"displayName":"Nurtan Bilmis","userId":"08002031282163870915"},"user_tz":-60},"id":"nbjnYjkssOhc"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.metrics import mean_absolute_error as MSE\n","X_train, X_test, y_train, y_test = train_test_split(X,y,\n","                                                    test_size=0.3,\n","                                                    random_state=0)\n","\n","gr_boost = GradientBoostingRegressor(n_estimators=300, max_depth=1, random_state=0)\n","gr_boost.fit(X_train, y_train)\n","y_pred = gr_boost.predict(X_test)\n","\n","rmse_test = MSE(y_test, y_pred) ** (1/2)\n","print(rmse_test)"]},{"cell_type":"markdown","metadata":{"id":"mS1R5ZxGFRZp"},"source":["### 5D Stochastic Gradient boosting\n","- Train een Stochastic Gradient Boosting classifier, maak daarbij een \"educated guess\" voor de parameter max_depth en het aantal trees.\n","- Beoordeel de uitkomst aan de hand van de f1 score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fiscHGxHsOhc"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"4suXzXTBsOhd"},"source":["## 6 Tuning\n","Tuning met grid search van random forests en boosting modellen is erg tijdrovend omdat het lang duurt om een model te trainen. Bij gridsearch wordt ook cross validation toegepast waardoor het model erg vaak getraind wordt.\n"]},{"cell_type":"markdown","metadata":{"id":"SSQdriHkGIBm"},"source":["### 6A Toepassen gridsearch\n","- Pas gridsearch met crossvalidation toe op 3 modellen:\n","  - Decision Tree\n","  - Random forest\n","  - Gradient boosting of ADA boosting\n","- Beschrijf je ervaringen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Z5slsS4sOhd"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","param_grid = \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60wUEe3yKOSY"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vrcpOP9KsOhe"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dn4HuywisOhe"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}